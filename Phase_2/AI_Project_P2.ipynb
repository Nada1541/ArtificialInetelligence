{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from shutil import get_terminal_size\n",
        "from collections import deque\n",
        "import time\n",
        "from itertools import count\n",
        "import math\n",
        "from tabulate import tabulate\n",
        "import sys\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "jv6CSO0ud0N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code to visualize the problem**\n"
      ],
      "metadata": {
        "id": "jf0ZJO16vJ8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "terminal_width, _ = get_terminal_size()\n",
        "_visualizers = {}\n",
        "\n",
        "def _default_visualizer(_, state):\n",
        "    print(state)\n",
        "\n",
        "class Visualizer:\n",
        "    def __init__(self, problem):\n",
        "        self.problem = problem\n",
        "        self.counter = 0\n",
        "\n",
        "    def visualize(self, frontier):\n",
        "        self.counter += 1\n",
        "        print(f'Frontier at step {self.counter}')\n",
        "        for node in frontier:\n",
        "            _visualizers.get(type(self.problem), _default_visualizer)(self.problem, node.state)\n",
        "        print('-' * terminal_width)\n",
        "\n",
        "    def visualize_state(self, state=None):\n",
        "        if state is None:\n",
        "            state = self.problem.init_state\n",
        "        self.counter += 1\n",
        "        print(f'Visualizing state at step {self.counter}')\n",
        "        _visualizers.get(type(self.problem), _default_visualizer)(self.problem, state)\n",
        "        print('-' * terminal_width)\n"
      ],
      "metadata": {
        "id": "nSCTMD9MaWBv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The problem class Robot_path**"
      ],
      "metadata": {
        "id": "POITJ6OAvOLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Robot_Path():\n",
        "      def __init__(self, init_state, goal_state, grid_size, obstacles=None):\n",
        "        #assert is a function to make sure that entered initial and goal states are not outside of grid\n",
        "        assert 0 <= init_state[0] < grid_size[0] and 0 <= init_state[1] < grid_size[1]\n",
        "        assert 0 <= goal_state[0] < grid_size[0] and 0 <= goal_state[1] < grid_size[1]\n",
        "        self._grid_size = grid_size\n",
        "        self.init_state = init_state\n",
        "        self._goal_state = goal_state\n",
        "        self.obstacles = set(obstacles) if obstacles else set()\n",
        "        self._action_values = {'up': (-1,0), 'down': (+1,0), 'left': (0,-1), 'right': (0,+1)}\n",
        "        self.goal_reward = 100\n",
        "        self.step_cost = -1\n",
        "        self.obstacle_penalty = -100\n",
        "\n",
        "      def actions(self, state):\n",
        "        x,y = state\n",
        "        possible_moves = []\n",
        "        for action, (dx, dy) in self._action_values.items():\n",
        "            next_state = (x + dx, y + dy)\n",
        "            if (0 <= next_state[0] < self._grid_size[0] and\n",
        "                0 <= next_state[1] < self._grid_size[1] and\n",
        "                next_state not in self.obstacles):\n",
        "                possible_moves.append(action)\n",
        "        return possible_moves\n",
        "\n",
        "      def result(self, state, action):\n",
        "        \"\"\"Apply an action and return the resulting state.\"\"\"\n",
        "        x, y = state\n",
        "        dx, dy = self._action_values[action]\n",
        "        next_state = (x + dx, y + dy)\n",
        "        if next_state not in self.obstacles and 0 <= next_state[0] < self._grid_size[0] and 0 <= next_state[1] < self._grid_size[1]:\n",
        "            return next_state\n",
        "        return state\n",
        "\n",
        "      def goal_test(self, state):\n",
        "        return state == self._goal_state\n",
        "\n",
        "      def reward(self, state, action):\n",
        "        \"\"\"Return the reward for taking an action in a state.\"\"\"\n",
        "        next_state = self.result(state, action)\n",
        "        if next_state == self._goal_state:\n",
        "            return self.goal_reward\n",
        "        elif next_state in self.obstacles:\n",
        "            return self.obstacle_penalty\n",
        "        return self.step_cost\n",
        "\n",
        "def visualize_grid(problem, state):\n",
        "    \"\"\"Visualize the grid environment.\"\"\"\n",
        "    grid = [['.' for _ in range(problem._grid_size[1])] for _ in range(problem._grid_size[0])]\n",
        "    for ox, oy in problem.obstacles:\n",
        "        grid[ox][oy] = 'X'\n",
        "    goal_x, goal_y = problem._goal_state\n",
        "    grid[goal_x][goal_y] = 'G'\n",
        "    state_x, state_y = state\n",
        "    grid[state_x][state_y] = 'A'\n",
        "    for row in grid:\n",
        "        print(' '.join(row))\n",
        "_visualizers[Robot_Path] = visualize_grid"
      ],
      "metadata": {
        "id": "UES7s6-wVTom"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate problem**"
      ],
      "metadata": {
        "id": "u-QiYCoKvUSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5\n",
        "obstacles = [(1, 1), (2, 2), (3, 3)]\n",
        "problem = Robot_Path((0,0),(n-1,n-1), (n,n), obstacles)\n",
        "visualize_grid(problem, problem.init_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FmnXBzqbCnk",
        "outputId": "b9ec0d7b-11f9-4bff-a990-9b69e82eebb7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A . . . .\n",
            ". X . . .\n",
            ". . X . .\n",
            ". . . X .\n",
            ". . . . G\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Valid Actions from Initial State:\", problem.actions(problem.init_state))\n",
        "next_state = problem.result(problem.init_state, 'right')\n",
        "print(\"Next State after moving 'right':\", next_state)\n",
        "reward = problem.reward(problem.init_state, 'right')\n",
        "print(\"Reward for moving 'right':\", reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvtDFzqOcZwR",
        "outputId": "4dfe340d-7773-4b0d-bb04-1f5e6be11e81"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Actions from Initial State: ['down', 'right']\n",
            "Next State after moving 'right': (0, 1)\n",
            "Reward for moving 'right': -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "problem.current_state = problem.result(problem.init_state, 'right')\n",
        "visualize_grid(problem, problem.current_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkEn4dTXcdjz",
        "outputId": "e6fad2f0-6510-4958-b726-ebfef82799d1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". A . . .\n",
            ". X . . .\n",
            ". . X . .\n",
            ". . . X .\n",
            ". . . . G\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QLearningAgent:\n",
        "    def __init__(self, problem, alpha=0.01, gamma=0.99, epsilon=0.5, Ne=5, Rplus=2):\n",
        "        self.problem = problem\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.Ne = Ne\n",
        "        self.Rplus = Rplus\n",
        "        self.Q = defaultdict(float)\n",
        "        self.Nsa = defaultdict(int)\n",
        "        self.state = problem.init_state\n",
        "        self.action = None\n",
        "        self.reward = 0\n",
        "#exploration function\n",
        "    def f(self, u, n):\n",
        "\n",
        "        return self.Rplus if n < self.Ne else u\n",
        "\n",
        "    def select_action(self, state):\n",
        "        actions = self.problem.actions(state)\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.choice(actions)\n",
        "        return max(actions, key=lambda a: self.f(self.Q[(state, a)], self.Nsa[(state, a)]))\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        self.Nsa[(state, action)] += 1\n",
        "        best_next_q = max([self.Q[(next_state, a)] for a in self.problem.actions(next_state)], default=0)\n",
        "        self.Q[(state, action)] += self.alpha * (reward + self.gamma * best_next_q - self.Q[(state, action)])\n",
        "\n",
        "\n",
        "    def train(self, episodes=100000):\n",
        "        for episode in range(episodes):\n",
        "            state = self.problem.init_state\n",
        "            self.epsilon = max(0.1, self.epsilon * 0.995)\n",
        "            while not self.problem.goal_test(state):\n",
        "                action = self.select_action(state)\n",
        "                next_state = self.problem.result(state, action)\n",
        "                reward = self.problem.reward(state, action)\n",
        "                self.update(state, action, reward, next_state)\n",
        "                state = next_state\n",
        "\n",
        "            # midway monitoring\n",
        "            if episode == episodes // 2:\n",
        "                print(\"\\n Midway Q-Values:\")\n",
        "                for (state, action), value in self.Q.items():\n",
        "                    print(f\"State: {state}, Action: {action}, Q-Value: {value:.2f}\")\n",
        "                print(\"\\n Midway Policy:\")\n",
        "                midway_policy = self.get_policy()\n",
        "                for state, action in midway_policy.items():\n",
        "                    print(f\"State: {state}, Action: {action}\")\n",
        "\n",
        "    def get_policy(self):\n",
        "        policy = {}\n",
        "        # iterate through possible states in the grid\n",
        "        for x in range(self.problem._grid_size[0]):\n",
        "            for y in range(self.problem._grid_size[1]):\n",
        "                state = (x, y)\n",
        "                actions = self.problem.actions(state)\n",
        "                if actions:\n",
        "                    policy[state] = max(actions, key=lambda a: self.Q[(state, a)])\n",
        "        return policy"
      ],
      "metadata": {
        "id": "R7YADLAP32zF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train Q-Learning Agent\n",
        "q_agent = QLearningAgent(problem)\n",
        "q_agent.train(episodes=100000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCS4K5NB5jOn",
        "outputId": "c8d42721-f3e4-462e-d755-7559a9f2ffcf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Midway Q-Values:\n",
            "State: (0, 0), Action: down, Q-Value: 86.41\n",
            "State: (0, 0), Action: right, Q-Value: 82.70\n",
            "State: (1, 0), Action: up, Q-Value: 84.55\n",
            "State: (1, 0), Action: down, Q-Value: 88.30\n",
            "State: (0, 1), Action: left, Q-Value: 84.55\n",
            "State: (0, 1), Action: right, Q-Value: 6.56\n",
            "State: (0, 2), Action: down, Q-Value: -0.87\n",
            "State: (0, 2), Action: left, Q-Value: 2.97\n",
            "State: (0, 2), Action: right, Q-Value: 16.44\n",
            "State: (1, 2), Action: up, Q-Value: -0.63\n",
            "State: (1, 2), Action: right, Q-Value: 4.24\n",
            "State: (1, 3), Action: up, Q-Value: 0.20\n",
            "State: (1, 3), Action: down, Q-Value: -0.07\n",
            "State: (1, 3), Action: left, Q-Value: -0.34\n",
            "State: (1, 3), Action: right, Q-Value: 53.36\n",
            "State: (2, 3), Action: up, Q-Value: -0.05\n",
            "State: (2, 3), Action: right, Q-Value: 7.77\n",
            "State: (0, 3), Action: down, Q-Value: 32.27\n",
            "State: (0, 3), Action: left, Q-Value: -0.51\n",
            "State: (0, 3), Action: right, Q-Value: -0.18\n",
            "State: (0, 4), Action: down, Q-Value: 9.80\n",
            "State: (0, 4), Action: left, Q-Value: -0.08\n",
            "State: (1, 4), Action: up, Q-Value: 0.13\n",
            "State: (1, 4), Action: down, Q-Value: 73.95\n",
            "State: (1, 4), Action: left, Q-Value: 2.40\n",
            "State: (2, 4), Action: up, Q-Value: 3.87\n",
            "State: (2, 4), Action: down, Q-Value: 89.53\n",
            "State: (2, 4), Action: left, Q-Value: -0.04\n",
            "State: (3, 4), Action: up, Q-Value: 11.29\n",
            "State: (3, 4), Action: down, Q-Value: 98.11\n",
            "State: (2, 0), Action: up, Q-Value: 86.41\n",
            "State: (2, 0), Action: down, Q-Value: 90.20\n",
            "State: (2, 0), Action: right, Q-Value: 90.20\n",
            "State: (2, 1), Action: down, Q-Value: 92.12\n",
            "State: (2, 1), Action: left, Q-Value: 88.30\n",
            "State: (3, 1), Action: up, Q-Value: 90.20\n",
            "State: (3, 1), Action: down, Q-Value: 94.06\n",
            "State: (3, 1), Action: left, Q-Value: 90.20\n",
            "State: (3, 1), Action: right, Q-Value: 94.06\n",
            "State: (3, 0), Action: up, Q-Value: 61.40\n",
            "State: (3, 0), Action: down, Q-Value: 54.60\n",
            "State: (3, 0), Action: right, Q-Value: 92.12\n",
            "State: (4, 1), Action: up, Q-Value: 92.12\n",
            "State: (4, 1), Action: left, Q-Value: 92.12\n",
            "State: (4, 1), Action: right, Q-Value: 96.02\n",
            "State: (4, 4), Action: up, Q-Value: 0.00\n",
            "State: (4, 4), Action: left, Q-Value: 0.00\n",
            "State: (4, 0), Action: up, Q-Value: 50.06\n",
            "State: (4, 0), Action: right, Q-Value: 94.06\n",
            "State: (3, 2), Action: down, Q-Value: 96.02\n",
            "State: (3, 2), Action: left, Q-Value: 76.53\n",
            "State: (4, 2), Action: up, Q-Value: 94.06\n",
            "State: (4, 2), Action: left, Q-Value: 94.06\n",
            "State: (4, 2), Action: right, Q-Value: 98.00\n",
            "State: (4, 3), Action: left, Q-Value: 96.02\n",
            "State: (4, 3), Action: right, Q-Value: 100.00\n",
            "\n",
            " Midway Policy:\n",
            "State: (0, 0), Action: down\n",
            "State: (0, 1), Action: left\n",
            "State: (0, 2), Action: right\n",
            "State: (0, 3), Action: down\n",
            "State: (0, 4), Action: down\n",
            "State: (1, 0), Action: down\n",
            "State: (1, 1), Action: up\n",
            "State: (1, 2), Action: right\n",
            "State: (1, 3), Action: right\n",
            "State: (1, 4), Action: down\n",
            "State: (2, 0), Action: right\n",
            "State: (2, 1), Action: down\n",
            "State: (2, 2), Action: up\n",
            "State: (2, 3), Action: right\n",
            "State: (2, 4), Action: down\n",
            "State: (3, 0), Action: right\n",
            "State: (3, 1), Action: down\n",
            "State: (3, 2), Action: down\n",
            "State: (3, 3), Action: up\n",
            "State: (3, 4), Action: down\n",
            "State: (4, 0), Action: right\n",
            "State: (4, 1), Action: right\n",
            "State: (4, 2), Action: right\n",
            "State: (4, 3), Action: right\n",
            "State: (4, 4), Action: up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Q-Values:\")\n",
        "for (state, action), value in q_agent.Q.items():\n",
        "    print(f\"State: {state}, Action: {action}, Q-Value: {value:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeKoEPBw4ORZ",
        "outputId": "89a9b322-7bc4-403c-e43b-34a87095c77c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-Values:\n",
            "State: (0, 0), Action: down, Q-Value: 86.41\n",
            "State: (0, 0), Action: right, Q-Value: 82.70\n",
            "State: (1, 0), Action: up, Q-Value: 84.55\n",
            "State: (1, 0), Action: down, Q-Value: 88.30\n",
            "State: (0, 1), Action: left, Q-Value: 84.55\n",
            "State: (0, 1), Action: right, Q-Value: 22.51\n",
            "State: (0, 2), Action: down, Q-Value: -0.67\n",
            "State: (0, 2), Action: left, Q-Value: 6.87\n",
            "State: (0, 2), Action: right, Q-Value: 37.09\n",
            "State: (1, 2), Action: up, Q-Value: -0.63\n",
            "State: (1, 2), Action: right, Q-Value: 7.28\n",
            "State: (1, 3), Action: up, Q-Value: 1.42\n",
            "State: (1, 3), Action: down, Q-Value: 0.48\n",
            "State: (1, 3), Action: left, Q-Value: -0.30\n",
            "State: (1, 3), Action: right, Q-Value: 72.91\n",
            "State: (2, 3), Action: up, Q-Value: 0.57\n",
            "State: (2, 3), Action: right, Q-Value: 17.18\n",
            "State: (0, 3), Action: down, Q-Value: 54.60\n",
            "State: (0, 3), Action: left, Q-Value: 0.26\n",
            "State: (0, 3), Action: right, Q-Value: 1.13\n",
            "State: (0, 4), Action: down, Q-Value: 18.25\n",
            "State: (0, 4), Action: left, Q-Value: -0.08\n",
            "State: (1, 4), Action: up, Q-Value: 0.41\n",
            "State: (1, 4), Action: down, Q-Value: 86.94\n",
            "State: (1, 4), Action: left, Q-Value: 5.31\n",
            "State: (2, 4), Action: up, Q-Value: 6.08\n",
            "State: (2, 4), Action: down, Q-Value: 95.32\n",
            "State: (2, 4), Action: left, Q-Value: 0.82\n",
            "State: (3, 4), Action: up, Q-Value: 18.23\n",
            "State: (3, 4), Action: down, Q-Value: 99.51\n",
            "State: (2, 0), Action: up, Q-Value: 86.41\n",
            "State: (2, 0), Action: down, Q-Value: 90.20\n",
            "State: (2, 0), Action: right, Q-Value: 90.20\n",
            "State: (2, 1), Action: down, Q-Value: 92.12\n",
            "State: (2, 1), Action: left, Q-Value: 88.30\n",
            "State: (3, 1), Action: up, Q-Value: 90.20\n",
            "State: (3, 1), Action: down, Q-Value: 94.06\n",
            "State: (3, 1), Action: left, Q-Value: 90.20\n",
            "State: (3, 1), Action: right, Q-Value: 94.06\n",
            "State: (3, 0), Action: up, Q-Value: 87.61\n",
            "State: (3, 0), Action: down, Q-Value: 91.53\n",
            "State: (3, 0), Action: right, Q-Value: 92.12\n",
            "State: (4, 1), Action: up, Q-Value: 92.12\n",
            "State: (4, 1), Action: left, Q-Value: 92.12\n",
            "State: (4, 1), Action: right, Q-Value: 96.02\n",
            "State: (4, 4), Action: up, Q-Value: 0.00\n",
            "State: (4, 4), Action: left, Q-Value: 0.00\n",
            "State: (4, 0), Action: up, Q-Value: 77.18\n",
            "State: (4, 0), Action: right, Q-Value: 94.06\n",
            "State: (3, 2), Action: down, Q-Value: 96.02\n",
            "State: (3, 2), Action: left, Q-Value: 88.87\n",
            "State: (4, 2), Action: up, Q-Value: 94.06\n",
            "State: (4, 2), Action: left, Q-Value: 94.06\n",
            "State: (4, 2), Action: right, Q-Value: 98.00\n",
            "State: (4, 3), Action: left, Q-Value: 96.02\n",
            "State: (4, 3), Action: right, Q-Value: 100.00\n",
            "State: (1, 1), Action: up, Q-Value: 0.00\n",
            "State: (1, 1), Action: down, Q-Value: 0.00\n",
            "State: (1, 1), Action: left, Q-Value: 0.00\n",
            "State: (1, 1), Action: right, Q-Value: 0.00\n",
            "State: (2, 2), Action: up, Q-Value: 0.00\n",
            "State: (2, 2), Action: down, Q-Value: 0.00\n",
            "State: (2, 2), Action: left, Q-Value: 0.00\n",
            "State: (2, 2), Action: right, Q-Value: 0.00\n",
            "State: (3, 3), Action: up, Q-Value: 0.00\n",
            "State: (3, 3), Action: down, Q-Value: 0.00\n",
            "State: (3, 3), Action: left, Q-Value: 0.00\n",
            "State: (3, 3), Action: right, Q-Value: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Policy\n",
        "policy = q_agent.get_policy()\n",
        "print(\"Policy:\")\n",
        "for state, action in policy.items():\n",
        "    print(f\"State: {state}, Action: {action}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba43tmhV4Q-B",
        "outputId": "90bb89de-d596-40c6-fd33-fcf1ccfe1e56"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Policy:\n",
            "State: (0, 0), Action: down\n",
            "State: (0, 1), Action: left\n",
            "State: (0, 2), Action: right\n",
            "State: (0, 3), Action: down\n",
            "State: (0, 4), Action: down\n",
            "State: (1, 0), Action: down\n",
            "State: (1, 1), Action: up\n",
            "State: (1, 2), Action: right\n",
            "State: (1, 3), Action: right\n",
            "State: (1, 4), Action: down\n",
            "State: (2, 0), Action: down\n",
            "State: (2, 1), Action: down\n",
            "State: (2, 2), Action: up\n",
            "State: (2, 3), Action: right\n",
            "State: (2, 4), Action: down\n",
            "State: (3, 0), Action: right\n",
            "State: (3, 1), Action: down\n",
            "State: (3, 2), Action: down\n",
            "State: (3, 3), Action: up\n",
            "State: (3, 4), Action: down\n",
            "State: (4, 0), Action: right\n",
            "State: (4, 1), Action: right\n",
            "State: (4, 2), Action: right\n",
            "State: (4, 3), Action: right\n",
            "State: (4, 4), Action: up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_q_policy(agent, problem):\n",
        "    grid = [['.' for _ in range(problem._grid_size[1])] for _ in range(problem._grid_size[0])]\n",
        "    for state, action in agent.get_policy().items():\n",
        "        if action == 'up':\n",
        "            symbol = '^'\n",
        "        elif action == 'down':\n",
        "            symbol = 'v'\n",
        "        elif action == 'left':\n",
        "            symbol = '<'\n",
        "        elif action == 'right':\n",
        "            symbol = '>'\n",
        "        else:\n",
        "            symbol = '.'\n",
        "        grid[state[0]][state[1]] = symbol\n",
        "    for row in grid:\n",
        "        print(' '.join(row))\n",
        "\n",
        "visualize_q_policy(q_agent, problem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOCZoNDhrE6C",
        "outputId": "8cf1a170-aae0-494e-ff6e-8f5f312c2f5e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v < > v v\n",
            "v ^ > > v\n",
            "v v ^ > v\n",
            "> v v ^ v\n",
            "> > > > ^\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate utilities from Q-Values\n",
        "U = defaultdict(lambda: -1000.)\n",
        "for (state, action), value in q_agent.Q.items():\n",
        "    if U[state] < value:\n",
        "        U[state] = value\n",
        "\n",
        "print(\" Final State Utilities:\")\n",
        "for state, utility in U.items():\n",
        "    print(f\"State: {state}, Utility: {utility:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rggS6D5O3M3k",
        "outputId": "e97d8d1f-176a-4026-c3df-60fc4939f1b2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Final State Utilities:\n",
            "State: (0, 0), Utility: 86.41\n",
            "State: (1, 0), Utility: 88.30\n",
            "State: (0, 1), Utility: 84.55\n",
            "State: (0, 2), Utility: 37.09\n",
            "State: (1, 2), Utility: 7.28\n",
            "State: (1, 3), Utility: 72.91\n",
            "State: (2, 3), Utility: 17.18\n",
            "State: (0, 3), Utility: 54.60\n",
            "State: (0, 4), Utility: 18.25\n",
            "State: (1, 4), Utility: 86.94\n",
            "State: (2, 4), Utility: 95.32\n",
            "State: (3, 4), Utility: 99.51\n",
            "State: (2, 0), Utility: 90.20\n",
            "State: (2, 1), Utility: 92.12\n",
            "State: (3, 1), Utility: 94.06\n",
            "State: (3, 0), Utility: 92.12\n",
            "State: (4, 1), Utility: 96.02\n",
            "State: (4, 4), Utility: 0.00\n",
            "State: (4, 0), Utility: 94.06\n",
            "State: (3, 2), Utility: 96.02\n",
            "State: (4, 2), Utility: 98.00\n",
            "State: (4, 3), Utility: 100.00\n",
            "State: (1, 1), Utility: 0.00\n",
            "State: (2, 2), Utility: 0.00\n",
            "State: (3, 3), Utility: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_utilities(problem, U):\n",
        "    grid = [['-' for _ in range(problem._grid_size[1])] for _ in range(problem._grid_size[0])]\n",
        "    for state, utility in U.items():\n",
        "        grid[state[0]][state[1]] = f\"{utility:.1f}\"\n",
        "    for row in grid:\n",
        "        print(' '.join(row))\n",
        "\n",
        "visualize_utilities(problem, U)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzArdZ4z4kQ0",
        "outputId": "c7fe0d5b-0d98-4954-91f6-024ce4b86033"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86.4 84.5 37.1 54.6 18.3\n",
            "88.3 0.0 7.3 72.9 86.9\n",
            "90.2 92.1 0.0 17.2 95.3\n",
            "92.1 94.1 96.0 0.0 99.5\n",
            "94.1 96.0 98.0 100.0 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_agent_path(problem, agent):\n",
        "    state = problem.init_state\n",
        "    path = [state]\n",
        "    while not problem.goal_test(state):\n",
        "        action = agent.select_action(state)\n",
        "        state = problem.result(state, action)\n",
        "        path.append(state)\n",
        "    print(\"Agent Movement Path:\")\n",
        "    print(\" -> \".join(map(str, path)))\n",
        "\n",
        "visualize_agent_path(problem, q_agent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BwGO3_23Rp7",
        "outputId": "037a24b1-95e9-47c7-9f1e-9858fed84246"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent Movement Path:\n",
            "(0, 0) -> (1, 0) -> (2, 0) -> (3, 0) -> (3, 1) -> (4, 1) -> (4, 2) -> (4, 3) -> (4, 4)\n"
          ]
        }
      ]
    }
  ]
}